{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare runs, choose a model, deploy it to a rest api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 11:49:43.082266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737440383.857806   18276 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737440384.105286   18276 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-21 11:49:45.940110: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from hyperopt import STATUS_OK, Trials,fmin,hp,tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.048</td>\n",
       "      <td>41.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.99256</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.054</td>\n",
       "      <td>23.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.99980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.041</td>\n",
       "      <td>24.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.99535</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.055</td>\n",
       "      <td>18.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99170</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>15.20</td>\n",
       "      <td>0.046</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.99665</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.047</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99418</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>54.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.043</td>\n",
       "      <td>28.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99129</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.035</td>\n",
       "      <td>53.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99567</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>38.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99255</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3673 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "2835            6.3              0.25         0.22            3.30      0.048   \n",
       "1157            7.8              0.30         0.29           16.85      0.054   \n",
       "744             7.4              0.38         0.27            7.50      0.041   \n",
       "1448            7.4              0.16         0.49            1.20      0.055   \n",
       "3338            7.2              0.27         0.28           15.20      0.046   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4426            6.2              0.21         0.52            6.50      0.047   \n",
       "466             7.0              0.14         0.32            9.00      0.039   \n",
       "3092            7.6              0.27         0.52            3.20      0.043   \n",
       "3772            6.3              0.24         0.29           13.70      0.035   \n",
       "860             8.1              0.27         0.35            1.70      0.030   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "2835                 41.0                 161.0  0.99256  3.16       0.50   \n",
       "1157                 23.0                 135.0  0.99980  3.16       0.38   \n",
       "744                  24.0                 160.0  0.99535  3.17       0.43   \n",
       "1448                 18.0                 150.0  0.99170  3.23       0.47   \n",
       "3338                  6.0                  41.0  0.99665  3.17       0.39   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4426                 28.0                 123.0  0.99418  3.22       0.49   \n",
       "466                  54.0                 141.0  0.99560  3.22       0.43   \n",
       "3092                 28.0                 152.0  0.99129  3.02       0.53   \n",
       "3772                 53.0                 134.0  0.99567  3.17       0.38   \n",
       "860                  38.0                 103.0  0.99255  3.22       0.63   \n",
       "\n",
       "      alcohol  quality  \n",
       "2835     10.5        6  \n",
       "1157      9.0        6  \n",
       "744      10.0        5  \n",
       "1448     11.2        6  \n",
       "3338     10.9        6  \n",
       "...       ...      ...  \n",
       "4426      9.9        6  \n",
       "466       9.4        6  \n",
       "3092     11.4        6  \n",
       "3772     10.6        6  \n",
       "860      10.4        8  \n",
       "\n",
       "[3673 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test= train_test_split(data,test_size=0.25, random_state=42)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.        ,  0.29      ,  0.41      , ...,  3.09      ,\n",
       "         0.59      , 10.96666667],\n",
       "       [ 5.4       ,  0.53      ,  0.16      , ...,  3.2       ,\n",
       "         0.53      , 13.2       ],\n",
       "       [ 7.1       ,  0.25      ,  0.39      , ...,  3.28      ,\n",
       "         0.43      , 12.2       ],\n",
       "       ...,\n",
       "       [ 5.9       ,  0.13      ,  0.28      , ...,  3.43      ,\n",
       "         0.64      , 10.8       ],\n",
       "       [ 6.8       ,  0.3       ,  0.29      , ...,  3.03      ,\n",
       "         0.32      , 12.9       ],\n",
       "       [ 7.4       ,  0.25      ,  0.36      , ...,  3.19      ,\n",
       "         0.44      , 10.8       ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)\n",
    "test_x=test.drop(['quality'],axis=1).values\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train.drop(['quality'],axis=1).values\n",
    "train_y = train[['quality']].values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=test.drop(['quality'],axis=1).values\n",
    "test_y = test[['quality']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x,train_y,valid_y=train_test_split(train_x,train_y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature=infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.27006361e-01, 1.04782780e-02, 1.41982590e-02, 2.63994276e+01,\n",
       "       4.46194261e-04, 2.83726450e+02, 1.74920842e+03, 9.23159572e-06,\n",
       "       2.25891723e-02, 1.24958983e-02, 1.49906782e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(train_x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params,epochs,train_x,train_y,valid_x,valid_y,test_x,test_y):\n",
    "    #mean of each feature for normalization\n",
    "    mean=np.mean(train_x,axis=0) \n",
    "    var=np.var(train_x,axis=0)\n",
    "    model= keras.Sequential([\n",
    "        keras.Input([train_x.shape[1]]),\n",
    "        keras.layers.Normalization(mean=mean,variance=var),\n",
    "        keras.layers.Dense(64,activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=params[\"lr\"],momentum=params[\"momentum\"]),\n",
    "                  loss=\"mean_squared_error\",\n",
    "                  metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    ##Train the ANN model with lr and with mlflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "                  epochs=epochs,batch_size=64)\n",
    "        eval_result=model.evaluate(valid_x,valid_y,batch_size=64)\n",
    "        eval_rmse=eval_result[1]\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\",eval_rmse)\n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "        return {\"loss\":eval_rmse,\"status\":STATUS_OK,\"model\":model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    result=train_model(params,epochs=3,train_x=train_x,train_y=train_y,valid_x=valid_x,valid_y=valid_y,test_x=test_x,test_y=test_y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"lr\":hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\",0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 333ms/step - loss: 36.1661 - root_mean_squared_error: 6.0138\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35.5160 - root_mean_squared_error: 5.9593\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 35.0576 - root_mean_squared_error: 5.9079   \n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.9080 - root_mean_squared_error: 5.8947   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.5775 - root_mean_squared_error: 5.4302 - val_loss: 15.7307 - val_root_mean_squared_error: 3.9662\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16.9029 - root_mean_squared_error: 4.0352\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 15.8879 - root_mean_squared_error: 3.9848\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 16.2887 - root_mean_squared_error: 3.9848\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15.7044 - root_mean_squared_error: 3.9618\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15.5330 - root_mean_squared_error: 3.9118\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15.4030 - root_mean_squared_error: 3.9118\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15.3103 - root_mean_squared_error: 3.9118 \n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.2141 - root_mean_squared_error: 3.8995 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8989 - root_mean_squared_error: 3.5855 - val_loss: 6.7993 - val_root_mean_squared_error: 2.6076\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.1691 - root_mean_squared_error: 2.6775\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9268 - root_mean_squared_error: 2.6315\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0123 - root_mean_squared_error: 2.6477\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0109 - root_mean_squared_error: 2.6475\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8864 - root_mean_squared_error: 2.6238\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9751 - root_mean_squared_error: 2.6344\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9415 - root_mean_squared_error: 2.6238 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8229 - root_mean_squared_error: 2.4092 - val_loss: 3.4479 - val_root_mean_squared_error: 1.8568\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1813 - root_mean_squared_error: 1.7836\n",
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1547 - root_mean_squared_error: 1.7761\n",
      "\u001b[1m 3/12\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2391 - root_mean_squared_error: 1.7994 \n",
      "\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3125 - root_mean_squared_error: 1.8195 \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3576 - root_mean_squared_error: 1.8321\n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 317ms/step - loss: 37.6697 - root_mean_squared_error: 6.1376\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.8353 - root_mean_squared_error: 6.1510\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.1464 - root_mean_squared_error: 6.2286   \n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.7987 - root_mean_squared_error: 6.2286   \n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.6834 - root_mean_squared_error: 6.2286   \n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4642 - root_mean_squared_error: 6.2286   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 38.9340 - root_mean_squared_error: 6.2397 - val_loss: 38.7872 - val_root_mean_squared_error: 6.2279\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 37.8987 - root_mean_squared_error: 6.1562\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.2347 - root_mean_squared_error: 6.1834\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.3713 - root_mean_squared_error: 6.2030 \n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4783 - root_mean_squared_error: 6.2030 \n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4061 - root_mean_squared_error: 6.2030 \n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4823 - root_mean_squared_error: 6.2034 \n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.3265 - root_mean_squared_error: 6.2034 \n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.3051 - root_mean_squared_error: 6.2034 \n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4318 - root_mean_squared_error: 6.2071 \n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38.4667 - root_mean_squared_error: 6.2004\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38.4345 - root_mean_squared_error: 6.1995\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38.4558 - root_mean_squared_error: 6.2004\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38.4453 - root_mean_squared_error: 6.1986\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4238 - root_mean_squared_error: 6.1986\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4126 - root_mean_squared_error: 6.1969\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4027 - root_mean_squared_error: 6.1969\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.3932 - root_mean_squared_error: 6.1962 - val_loss: 37.9333 - val_root_mean_squared_error: 6.1590\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.2545 - root_mean_squared_error: 6.2093\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38.5563 - root_mean_squared_error: 6.2093\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.9655 - root_mean_squared_error: 6.1462\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38.3605 - root_mean_squared_error: 6.1462\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.1547 - root_mean_squared_error: 6.1303\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.6622 - root_mean_squared_error: 6.1303\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.7788 - root_mean_squared_error: 6.1303\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.5831 - root_mean_squared_error: 6.1303\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.5193 - root_mean_squared_error: 6.1220\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.4815 - root_mean_squared_error: 6.1180\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.4330 - root_mean_squared_error: 6.1180 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.2115 - root_mean_squared_error: 6.1001 - val_loss: 37.1010 - val_root_mean_squared_error: 6.0911\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 37.7149 - root_mean_squared_error: 6.1412\n",
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 37.3247 - root_mean_squared_error: 6.1093\n",
      "\u001b[1m 3/12\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.9394 - root_mean_squared_error: 6.0776\n",
      "\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.8974 - root_mean_squared_error: 6.0742\n",
      "\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.8832 - root_mean_squared_error: 6.0730\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.8707 - root_mean_squared_error: 6.0721\n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 336ms/step - loss: 38.5188 - root_mean_squared_error: 6.2063\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.5017 - root_mean_squared_error: 6.1969\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.4016 - root_mean_squared_error: 6.1892\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.1634 - root_mean_squared_error: 6.1776\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38.3064 - root_mean_squared_error: 6.1776\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.9997 - root_mean_squared_error: 6.1643   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 31.0944 - root_mean_squared_error: 5.5624 - val_loss: 13.0792 - val_root_mean_squared_error: 3.6165\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.0425 - root_mean_squared_error: 3.6216\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13.0688 - root_mean_squared_error: 3.6114\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.8117 - root_mean_squared_error: 3.5705\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.0156 - root_mean_squared_error: 3.5790\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.1163 - root_mean_squared_error: 3.6076\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.7510 - root_mean_squared_error: 3.5705\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.6829 - root_mean_squared_error: 3.5609\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.9022 - root_mean_squared_error: 3.5609\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.6378 - root_mean_squared_error: 3.5546\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.5798 - root_mean_squared_error: 3.5378\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.5196 - root_mean_squared_error: 3.5378\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.3910 - root_mean_squared_error: 3.2158\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.3488 - root_mean_squared_error: 3.2023\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.3068 - root_mean_squared_error: 3.2023\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2664 - root_mean_squared_error: 3.1958 - val_loss: 4.8764 - val_root_mean_squared_error: 2.2083\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1537 - root_mean_squared_error: 2.2264\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9626 - root_mean_squared_error: 2.1948\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8244 - root_mean_squared_error: 2.1717\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4056 - root_mean_squared_error: 2.2695\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7245 - root_mean_squared_error: 2.1553\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6532 - root_mean_squared_error: 2.1489\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5618 - root_mean_squared_error: 2.1302\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6248 - root_mean_squared_error: 2.1346\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5432 - root_mean_squared_error: 2.1202\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5843 - root_mean_squared_error: 2.1173\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6098 - root_mean_squared_error: 2.1346\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4877 - root_mean_squared_error: 2.1173\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5003 - root_mean_squared_error: 2.1100\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4405 - root_mean_squared_error: 2.0989\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4565 - root_mean_squared_error: 2.0989\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1110 - root_mean_squared_error: 2.0260\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1013 - root_mean_squared_error: 2.0236\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0923 - root_mean_squared_error: 2.0213\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0836 - root_mean_squared_error: 2.0192 - val_loss: 2.9033 - val_root_mean_squared_error: 1.7039\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.8476 - root_mean_squared_error: 1.6875\n",
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8599 - root_mean_squared_error: 1.6911\n",
      "\u001b[1m 3/12\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9346 - root_mean_squared_error: 1.7291 \n",
      "\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9913 - root_mean_squared_error: 1.7291 \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9487 - root_mean_squared_error: 1.7170\n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 327ms/step - loss: 30.7478 - root_mean_squared_error: 5.5451\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.4940 - root_mean_squared_error: 5.3338\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.6319 - root_mean_squared_error: 5.1513\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.8064 - root_mean_squared_error: 4.7914\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.2181 - root_mean_squared_error: 4.7914\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.8130 - root_mean_squared_error: 4.4868   \n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.9939 - root_mean_squared_error: 2.6611 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8940 - root_mean_squared_error: 2.6611 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.7984 - root_mean_squared_error: 2.6437 - val_loss: 1.3188 - val_root_mean_squared_error: 1.1484\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2803 - root_mean_squared_error: 1.1040\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 1.2195 - root_mean_squared_error: 1.1040\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2352 - root_mean_squared_error: 1.1111\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2167 - root_mean_squared_error: 1.0982\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2130 - root_mean_squared_error: 1.0982\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2245 - root_mean_squared_error: 1.1028\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2010 - root_mean_squared_error: 1.0922\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1933 - root_mean_squared_error: 1.0922\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1925 - root_mean_squared_error: 1.0918\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2065 - root_mean_squared_error: 1.0922\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1924 - root_mean_squared_error: 1.0918 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1352 - root_mean_squared_error: 1.0650 - val_loss: 0.9642 - val_root_mean_squared_error: 0.9819\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9612 - root_mean_squared_error: 0.9687\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.9217 - root_mean_squared_error: 0.9599\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.9385 - root_mean_squared_error: 0.9599\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9001 - root_mean_squared_error: 0.9451\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8936 - root_mean_squared_error: 0.9451\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8961 - root_mean_squared_error: 0.9408\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8911 - root_mean_squared_error: 0.9386\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8855 - root_mean_squared_error: 0.9386\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8814 - root_mean_squared_error: 0.9386\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8776 - root_mean_squared_error: 0.9366\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8755 - root_mean_squared_error: 0.9343\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8710 - root_mean_squared_error: 0.9331 \n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8734 - root_mean_squared_error: 0.9331 \n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8380 - root_mean_squared_error: 0.9147\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8359 - root_mean_squared_error: 0.9141\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8370 - root_mean_squared_error: 0.9141\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8348 - root_mean_squared_error: 0.9129\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8337 - root_mean_squared_error: 0.9129\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8326 - root_mean_squared_error: 0.9123 - val_loss: 0.7563 - val_root_mean_squared_error: 0.8697\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7099 - root_mean_squared_error: 0.8426\n",
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6842 - root_mean_squared_error: 0.8270\n",
      "\u001b[1m 3/12\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7159 - root_mean_squared_error: 0.8547\n",
      "\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7315 - root_mean_squared_error: 0.8547\n",
      "\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7377 - root_mean_squared_error: 0.8585\n",
      "\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7414 - root_mean_squared_error: 0.8625 \n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7446 - root_mean_squared_error: 0.8625 \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7608 - root_mean_squared_error: 0.8720\n",
      "\n",
      "100%|██████████| 4/4 [00:53<00:00, 13.32s/trial, best loss: 0.8696722984313965]\n",
      "best params:{'lr': np.float64(0.014692571152305049), 'momentum': np.float64(0.32968963190957123)}\n",
      "best eval rmse:0.8696722984313965\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    trials=Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,algo=tpe.suggest,\n",
    "        max_evals=4,trials=trials\n",
    "\n",
    "    )\n",
    "\n",
    "    best_run= sorted(trials.results,key=lambda x:x[\"loss\"] )[0]\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\",best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"],\"models\",signature=signature)\n",
    "    print(f\"best params:{best}\")\n",
    "    print(f\"best eval rmse:{best_run['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/hashif/DATA/materials/ml_flow/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1891.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/39\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.5643997],\n",
       "       [6.9936132],\n",
       "       [6.3760576],\n",
       "       ...,\n",
       "       [6.51527  ],\n",
       "       [6.87061  ],\n",
       "       [5.257748 ]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "model_uri = 'runs:/e577cf908ed34a779edd63719dc8fd14/models'\n",
    "\n",
    "# The logged model does not contain an input_example.\n",
    "# Manually generate a serving payload to verify your model prior to deployment.\n",
    "from mlflow.models import convert_input_example_to_serving_input\n",
    "\n",
    "# Define INPUT_EXAMPLE via assignment with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "serving_payload = convert_input_example_to_serving_input(test_x)\n",
    "\n",
    "# Validate the serving payload works on the model\n",
    "validate_serving_input(model_uri, serving_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.register_model(model_uri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
